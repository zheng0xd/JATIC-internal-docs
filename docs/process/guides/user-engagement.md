# User Engagement Guide

Frequent user engagement helps our program understand the mission tasks, needs, and interests of the wider DoD community - enabling us to better build products that meet their needs.

This document covers the following topics:
- The program's high-level strategy for user engagement
- Key user-engagement categories and mechanisms for engaging different categories of users
- Key responsibilities for user engagement

## High-level strategy for user engagement

Our user engagement strategy has the following objectives:

- Identificication of priority AI domains, mission use cases, and T&E requirements across the DoD
- Identificication of the above for key user groups
- Promote clear traceability of these requirements from different users and organizations in our capability development process.
- Supporting active collaboration between tool users & the team to create a consistent feedback loop that allows us to ensure our delivered capabilities address priority needs across the DoD. 
- Developing, maintaining, and utilizing long-term partnerships with key users.

Each engagement will broadly involve these tasks:
1.  Sourcing and connecting with users (current or potential).
2.  Sharing the high-level vision for the program.
3.  Identifying T&E problems users are facing now or that they’re anticipating as they look to increase their adoption of AI. 
4.  Describing the products that might solve those problems that have been identified.
5.  Supporting users as they adopt our tools & capabilities.
6.  Continued conversations with users to receive input on other features they desire that can help shape development for existing tools or provide demand signals for additional tools that should be built into the program.

## Key user engagement categories

The program is targeting a diverse range of key users for engagement that includes stakeholders across the government, as well as non-government entities in academia and industry given the open-source nature of our tools. Below, please find a short description of these different categories of users and general recommendations for engaging with these audiences.

Specific goals for targeting priority users or user engagement will be identified each increment and shared as part of the increment planning process.

=== "DoD"

    Government employees and contractors for the Department of Defense include many categories of users that it will be valuable for the program to engage with.     Engaging with these users throughout the lifecycle of capability development & deployment directly feeds into our mission of producing software to accelerate and enable AI T&E for DoD testers and increase the safety, effectiveness, and robustness of the DoD’s AI-enabled systems.

    DoD government user types we target for engagement might include, but are not limited to:
    - AI Test & Evaluation Engineers
    - Persona 1: Alice: Basic AI T&E Engineer doing T&E (e.g. for unmanned ground vehicles)
    - Persona 2: Jay: Advanced AI T&E Engineer doing T&E (e.g. on satellite imagery)
    - The Alice & Jay [personas](https://app.mural.co/t/mitresandbox0478/m/mitresandbox0478/1693165466374/3484fce186f84fee231e1e584555cdcf7bc2f552?sender=c82d7e46-ee27-40a3-9bec-1ebf55573b17) can expand to include a multitude of AI tasks and domains requiring T&E.
    - Engagement with individuals in this group should focus on getting these users to begin or maintain active involvement, provide feedback on existing tools, or the identification of other priority AI tasks/domains relevant to the DoD that we should consider for future development.

    - ML Developers/Researchers
        - [Persona 3](https://app.mural.co/t/mitresandbox0478/m/mitresandbox0478/1693165466374/3484fce186f84fee231e1e584555cdcf7bc2f552?sender=c82d7e46-ee27-40a3-9bec-1ebf55573b17) – Fred: Manual ML Developer who needs to verify and validate models before starting field tests, create tests, and create reports on the best performing models.
    - Engagement with individuals in this group should focus on getting these users to begin or maintain active involvement, provide feedback on existing tools, or identifying other priority AI tasks/domains relevant to the DoD that we should consider for future development.

    - Leadership/Program Managers that are currently employing AI
    - These individuals will be looking for AI T&E capabilities that they can incorporate into existing programs. Unlikely to be users themselves, this audience will be searching for accessible tools and programs that will be easy to integrate with their technical teams.
    - Engagement with individuals in this group should focus on identifying problems they/their team are facing and presenting or developing our tools as solutions to those problems.

    - Leadership/Program Managers that are interested in employing AI in the future
    -These individuals are looking to improve their situational awareness of AI T&E problems and solutions that might apply to future AI-enabled systems they intend to use.
    - Engagement with individuals in this group should focus on identifying problems they & their team are facing with regards to AI adoption and sharing how our tools can help.

    Mechanisms for engagement:

    - Try to gather information about the attendees and their experience level before you meet with these users when possible. Be prepared to present the JATIC overview information ([Distribution C deck](https://gitlab.jatic.net/jatic/docs/presentations/-/blob/master/briefs/JATIC_Overview.pptx?ref_type=heads)) to teams without previous knowledge of the program. Be prepared to speak to tools & capabilities within JATIC that might be of particular interest given the user needs. This might include inviting others from the program to join your meeting or setting up follow-up meetings with specific JATIC teams including additional technical folks from your tool development team, other tool product owners, or members of the program management team.
    - Invite users to stay engaged with the program by joining the [GitLab](https://gitlab.jatic.net/) using their government/FFRDC/UARC email account, attending future quarterly demonstrations or weekly deep dives, filling out the [intake form](https://forms.osi.apps.mil/pages/responsepage.aspx?id=kQEtEK7uYUexyxqD6G70RffprThOa3hKghVjeesZps5UN1hXMDUxN1dXM0c3SUJZVE1FMU1PTDAyQi4u) to join our email list, or attend future events hosted by the program.
    - Some engagements might progress to the point of needing official government-to-government agreements between CDAO & the DoD office for specific partnership on a specific goal/mission (e.g. signing an MOU with an organization that we will provide their T&E tools). Keeping the program team apprised of outreach and engagements you have with DoD organizations using the [Partnerships Group in GitLab](https://gitlab.jatic.net/cdao/partnerships) is essential to ensure those select needs are identified early.
    - Ask these users if they have upcoming working group meetings, conferences, or other events that the program could attend and present at.

=== "Non-DoD Gov't"

    Employees and contractors who work within the government, but outside of DoD, include many similar users that can be found within the DoD category above. 
    Engaging with these non-DoD users allows us to expand our awareness of mission use cases, unique environments, and challenges that our capabilities can address in the use of AI-enabled systems across the US government. Input and feedback generated from these engagements can assist with refining our capabilities for maximum impact and expanded reach, as well as allow us to source demand signals for future capabilities that will also impact the DoD. 

    Non-DoD government user types we target for engagement might include, but are not limited to:

    - AI Test & Evaluation Engineers
    - Persona 1: Alice: Basic AI T&E Engineer doing T&E (e.g. for unmanned ground vehicles)
    - Persona 2: Jay: Advanced AI T&E Engineer doing T&E (e.g. on satellite imagery)
    - The Alice & Jay [personas](https://app.mural.co/t/mitresandbox0478/m/mitresandbox0478/1693165466374/3484fce186f84fee231e1e584555cdcf7bc2f552?sender=c82d7e46-ee27-40a3-9bec-1ebf55573b17) can expand to include a multitude of AI tasks and domains requiring T&E.
    - Engagement with individuals in this group should focus on getting these users to begin or maintain active involvement, provide feedback on existing tools, or the identification of other priority AI asks/domains relevant to the DoD that we should consider for future development.

    - ML Developers/Researchers
        - [Persona 3](https://app.mural.co/t/mitresandbox0478/m/mitresandbox0478/1693165466374/3484fce186f84fee231e1e584555cdcf7bc2f552?sender=c82d7e46-ee27-40a3-9bec-1ebf55573b17) – Fred: Manual ML Developer who needs to verify and validate models before starting field tests, create tests, and create reports on the best performing models.
    - Engagement with individuals in this group should focus on getting these users to begin or maintain active involvement, provide feedback on existing tools, or the identification of other priority AI asks/domains relevant to the DoD that we should consider for future development.

    - Leadership/Program Managers that are currently employing AI
    - These individuals will be looking for AI T&E capabilities that they can incorporate into existing programs. Unlikely to be users themselves, this audience will be searching for accessible tools and programs that will be easy to integrate with their technical teams.
    - Engagement with individuals in this group should focus on identifying problems they/their team are facing and presenting or developing our tools as solutions to those problems that are also relevant to the DoD.

    - Leadership/Program Managers that are interested in employing AI in the future
    -These individuals are looking to improve their situational awareness of AI T&E problems and solutions that might apply to future AI-enabled systems they intend to use.
    - Engagement with individuals in this group should focus on identifying problems they & their team are facing with regards to AI adoption and sharing how our tools can help.

    Mechanisms for engagement:

    - Try to gather information about the audience and their experience level before you meet with these users when possible. Be prepared to present the JATIC overview information ([Distribution C deck](https://gitlab.jatic.net/jatic/docs/presentations/-/blob/master/briefs/JATIC_Overview.pptx?ref_type=heads) to teams without previous knowledge of the program. Be prepared to speak to tools & capabilities within the program that might be of particular interest given the user needs. This might include inviting others from the program to join your meeting or setting up follow-up meetings that include additional technical folks from your tool development team, other tool product owners, or members of the program management team. 
    - Invite users to stay engaged with the program by joining the [GitLab](https://gitlab.jatic.net/) using their government/FFRDC/UARC email account, attending future quarterly demonstrations or weekly deep dives, filling out the [intake form](https://forms.osi.apps.mil/pages/responsepage.aspx?id=kQEtEK7uYUexyxqD6G70RffprThOa3hKghVjeesZps5UN1hXMDUxN1dXM0c3SUJZVE1FMU1PTDAyQi4u) to join our email list, or attend future events hosted by the program.
    - Some engagements might progress to the point of needing official government-to-government agreements between CDAO & the DoD office for specific partnership on a specific goal/mission (e.g. signing an MOU with an organization that we will provide their T&E tools). Keeping the team apprised of outreach and engagements you have with government organizations using the [Partnerships Group in GitLab](https://gitlab.jatic.net/cdao/partnerships) is essential to ensure those select needs are identified early.
    - Ask these users if they have upcoming working group meetings, conferences, or other events that the program could attend and present at.

=== "Academia"

    The program is designed to ensure that best practices and innovative research from the academic community are being brought into the DoD’s AI T&E capabilities.

    Engagement with the academic community throughout the development and deployment of AI T&E capabilities is important to ensure the program continues incorporating cutting edge research for our government clients. In addition to sourcing feedback and new research directions from academic partners, we also want to provide access and tooling that will benefit their communities and research through our open-source releases. 

    Academic user types we target for engagement might include, but are not limited to:

    - AI Researchers
    - ML Developers
    - Institute Directors/program Managers
    - Professors teaching the new generation of AI/T&E experts and the students themselves

    Engagement with individuals in this group should focus on getting these users to begin or maintain active involvement, provide feedback on existing tools, or assist with the identification of other priority AI asks/domains relevant to the DoD that we should consider for future development.

    Mechanisms for engagement:

    - Try to gather information about the audience and their research focus before you meet with academic users if possible. Be prepared to present a high-level overview of the program and its mission ([Distribution A deck](https://gitlab.jatic.net/home/frameworks/-/blob/main/CDAO_JATIC_Overview.pdf?ref_type=heads)). Be prepared to speak to tools & capabilities within the program that might be of particular interest given their interests, especially highlighting those tools that are already open-sourced to the public. This might include inviting others from the program to join your meeting or setting up follow-up meetings that include additional technical folks from your tool development team, other tool product owners, or members of the program management team.
    - Share our open-source tools with these audience members and encourage them to provide feedback through open-source platforms or directly to your teams.
    - Ask these users if they have upcoming working group meetings, conferences, or other events that the program could attend and present at.
    - Please note any engagements with academic organizations using the [Partnerships Group in GitLab](https://gitlab.jatic.net/cdao/partnerships).

=== "Industry"

    The program is designed to ensure that best practices and innovative research from industry are also being brought into the DoD’s AI T&E capabilities, both through industry leadership within the program and continued engagement with the broader industry community.

    Intentional engagement with industry will allow the program to fulfill its goal of transitioning best practices for T&E to the DoD in order to increase maturity and useability. In addition to receiving feedback from industry partners, we also want to encourage the adoption and use of our capabilities and standards across the industry community as we continue to release our tools publicly.

    Industry user types we target for engagement might include, but are not limited to:

    - AI Researchers
    - ML Developers
    - AI Red Teaming Professionals

    Engagement with individuals in this group should focus on getting these users to begin or maintain active involvement, provide feedback on existing tools, or assist with the identification of other priority AI asks/domains relevant to the DoD that we should consider for future development.

    Mechanisms for engagement:

    - Try to gather information about the audience and their research focus before you meet with academic users if possible. Be prepared to present a high-level overview of the program and its mission ([Distribution A deck](https://gitlab.jatic.net/home/frameworks/-/blob/main/CDAO_JATIC_Overview.pdf?ref_type=heads)). Be prepared to speak to tools & capabilities within the program that might be of particular interest given their interests, especially highlighting those tools that are already open-sourced to the public. This might include inviting others from the program to join your meeting or setting up follow-up meetings that include additional technical folks from your tool development team, other tool product owners, or members of the program management team.
    - Share our open-source tools with these audience members and encourage them to provide feedback through open-source platforms or directly to your teams.
    - Ask these users if they have upcoming working group meetings, conferences, or other events that the program could attend and present at.
    - Please note any engagements with academic organizations using the [Partnerships Group in GitLab](https://gitlab.jatic.net/cdao/partnerships).

## Key responsibilities for user engagement

### Product owners

Product owners serve a unique role in the user engagement process for both their development team and the overall program (see "[Agile Roles & Responsibilities](https://gitlab.jatic.net/jatic/docs/org-process/-/blob/main/Agile%20Roles%20and%20Responsibilities.md?ref_type=heads)"). Product owner responsibilities when it comes to user engagement include, but are not limited to:

- Understanding the program level vision for the program & being able to successfully present that vision to external audiences (using the JATIC Overview Distribution A or Distribution C deck.)
- Advocating for your specific tool/capability to a variety of users by presenting briefs, demos, and answering questions on it.
- Engaging with a broad range of potential users across the DoD, other government agencies, FFRDC/UARCs, academic, and industry organizations to determine future needs and tasks that your capability can serve. This includes documentation of these external engagements in the Partnerships Group in GitLab.
- Leading the execution of the user feedback strategy for your team by providing guidance and expertise about the users and their operational needs to the wider development team. This includes documentation of end-user requirements and feedback for your team and the program to incorporate.
- Presenting the public demonstration of your tool at the end of each increment.
- Overseeing the creation and maintenance of partnerships and feedback loops with priority AI tasks or exemplar users for the program.

### Program management team

The program management team’s responsibilities for user engagement include, but are not limited to:

- Promoting the program across key user bases & identifying strategic opportunities for engagement. 
- Lead higher-level "organization to organization" user engagements with key partners to establish MOUs or user agreements.
- Developing acquisition strategies for new products based on demand signals provided by external users.
- Providing high-level guidance to program teams about the priority use cases, exemplar users & personas that should be targeted on an annual & per increment basis.
- Identifying Product Owners who can support each tool/capability within the Program.
- Working with Product Owners to ensure user communities are informed in a timely manner about the program & its capabilities. This includes overseeing outreach activities such as quarterly capability demos, weekly deep dives, program partnerships, etc.
- Maintaining awareness of external engagements with key user groups to lead next-level engagements that require more formal commitments such as MOUs or user agreements.
- Providing frequent summary of capabilities to DoD/CDAO leadership.
 
### Development teams

A development team’s responsibilities for user engagement include, but are not limited to:

- Establishing the team environment, including best processes for working as a team to ensure capability delivery to a broad user base.
- Supporting product owners & program management in external outreach conversations or events where appropriate.
- Reporting requests for external engagement to their product owner to ensure proper documentation.
- Working with the product owner to incorporate feedback regarding priority AI tasks or exemplar users for the program.
