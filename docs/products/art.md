# Adversarial Robustness Toolbox (ART)

Adversarial Robustness Toolbox (ART) is a Python library for Machine Learning Security.

ART provides tools that enable developers and researchers to defend and evaluate Machine Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction, and Inference. ART supports all popular machine learning frameworks (TensorFlow, Keras, PyTorch, MXNet, scikit-learn, XGBoost, LightGBM, CatBoost, GPy, etc.), all data types (images, tables, audio, video, etc.) and machine learning tasks (classification, object detection, speech recognition, generation, certification, etc.).

- [ART github](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
- [ART documentation](https://adversarial-robustness-toolbox.readthedocs.io/)

```python
pip install adversarial-robustness-toolbox
```
## Contributing and feedback

As ART is still in the alpha development phase, end-user experience and internal testing are incredibly valuable to us.

- If you have a question about how to use the current protocols or other questions, we recommend using the [# collab-ibm](https://app.slack.com/huddle/T03PVG73TCP/C05FR87SBHC) channel on slack to start a discussion.
